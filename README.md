[![CI](https://github.com/nogibjj/SiMinL_Week10/actions/workflows/CI.yml/badge.svg)](https://github.com/nogibjj/SiMinL_Week10/actions/workflows/CI.yml)

# SiMinL_Week10 PySpark

# Requirements
- Use PySpark to perform data processing on a large dataset
- Include at least one Spark SQL query and one data transformation

# Purpose 
The project involves utilizing PySpark for data processing on a substantial dataset. The main objectives are to incorporate a Spark SQL query and execute a data transformation. I have used a Pokemon Dataset for this.

# Preparation
1. open codespaces
2. wait for environment to be installed
3. run: python main.py

# Procedure
- Extract the dataset via extract
- Start a spark session via start_spark
- Load the dataset via load_data
- Find some descriptive statistics via descibe
- Query the dataset via query
- Transformation on the sample dataset via example_transform
- End spark session via end_spark
